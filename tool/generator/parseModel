#!/usr/bin/env node
/* Mongo model parser
 * @author Michal Tanecek
 * @version 0.0.9
 * @licence BSD
 * @todo: Relations

 *Â version history:
 * 0.0.9:
 * no more JSON - using util.inspect + js-beautify
 * no more problem with functions
 * 0.0.8:
 * validators compatibility with node forms
 * removed functions for validators due to used form generator 
 * 0.0.7:
 * added support for ref
 * replace whitespaces with tab \x20{4} => \t
 * 0.0.6:
 * added support fot validate callback functions
 * added support for buld-in validators min,max,match
 * added toString functionality for default values - functions
 * fix for default values: false (Boolean ..)
 * add support for mongoose enum - select tag
 * remove forEach break hack
 * cleaned code
 * minor changes for tamplate
 * 0.0.5:
 * initial import
 */
var  program = require('commander')
	,fs = require('fs')
	,path = require('path')
	,beautify = require('js-beautify').js_beautify
	,util = require('util')
	;

var _model;
var _path;
var _schema = {};
var _modelFile;
var _patches = '//[patches\n\n\n//patches]';

var primitives = ['Email','Url','Number','Date','Boolean','String'];
var inputConversion = {'Email': 'email','Url': 'url', 'Number':'number','Date':'date','Boolean':'checkbox','String':'text'};
var marks = ['required','unique','disabled','disabled'];
var filters = ['lowercase' ,'uppercase','trim'];

program
  .version('0.0.9')
  .option('-m, --model [name]', 'Set model')
  .option('-p, --path [path]','Set custom model path', path.normalize('../../app/model'))
  .option('-f, --force','Force parser to rewrite exists file')
  .option('-r, --revision','Set model revision','0.0.1')
  .parse(process.argv);


if(!program.model) {
	console.error('Error: Provide model, for more information run script with --help argument.')
	process.exit();
}
_path = path.normalize(program.path);

if(program.model.match('/.js$/'))
	_modelFile = _path+'/'+program.model.replace('/.js$/','');
else
	_modelFile = _path+'/'+program.model;

_model = require(_modelFile);

var file = path.normalize(_path +'/'+program.model+'.parsed.js');

_schema = (util.inspect(parse(_model.schema.tree),{ showHidden: false, depth: null }))
_schema = (beautify(_schema, { indent_size: 4 }))


while(_schema.match(/\x20{4}/)) {
	_schema = _schema.replace(/\x20{4}/,'\t');
}

if(fs.existsSync(file) && !program.force) {
	var data = fs.readFileSync(file).toString();
	var patches = data.match(/\/\/\[patches(.|[\r\n])*\/\/patches\]/);
	if(Array.isArray(patches)) {
		patches = patches[0];
	}
	_patches = patches; 
} 
var _tmpl = [
	 '/*\n'
	,' * Parsed mongoose model - `#model#`\n'
	,' * @revision #revision#\n'
	,' * @parser_version #parser_version#\n'
	,' * @generated #iso#\n'
	,' */\n\n'
	,'//[\n'
	,'var model = {};\n'
	,'var mongooseModel = require(\'#modelFile#\');\n'
	,'model.schema = mongooseModel.schema;\n'
	,'model.entity = mongooseModel.model;\n'
	,'model.form = {};\n'
	,'var schema = '
	,'#schema#'
	,';\n'
	,'//]\n'
	,'#patches#'
	,'\nmodel.form.schema = schema;'
	,'\nexports = module.exports = model;'
];
var replaces = {
	 'model' : program.model
	,'revision': program.revision
	,'parser_version': program._version
	,'iso' : (new Date).toISOString()
	,'modelFile' : _modelFile
	,'schema': _schema
	,'patches' : _patches
};
_tmpl = vocabulary_replace(replaces,_tmpl.join(''));
fs.writeFileSync(file,_tmpl)


function vocabulary_replace(source,target) {
	var  strings = Object.getOwnPropertyNames(source)
		,i = 0;
	for(; i < strings.length; i++) {
		target = target.replace('#'+strings[i]+'#',source[strings[i]]);
	}
	return target;
}


function parse(source) {
	var target = {};
	var props = Object.getOwnPropertyNames(source);
	var i;
	for(i =0; i < props.length; i++) {
		// simple types
		if(typeof source[props[i]] == 'function') {
			var j;
			for(j =0; j < primitives.length; j++) {
				var item = primitives[j];
				var re = new RegExp(item,"g");
				if((source[props[i]].toString().match(re) || item == 'String') && (props[i] != '__v')) {
					target[props[i]] = {
						type: inputConversion[item]
					}
				}
			break;
			}
		} 
		// objects
		else {
			// field
			if(typeof source[props[i]].type != 'undefined') {
				var type = (source[props[i]].type.toString()).replace('function ','')
				if(props[i] == '_id') {
					target[props[i]] = {
						type: 'text',
						pk : true
					}
				} else {
					var j,found = false;
					for(j =0; j < primitives.length; j++) {
						var re = new RegExp('^'+primitives[j],"g");
						if(type.match(re)) {
							target[props[i]] = field(props[i],primitives[j],source[props[i]]);
							found = true;
							break;
						}						
					}
					if(!found) {
						// ref field
						if(type.match(/^ObjectId/)) {
							if(Array.isArray(source[props[i]].ref_to)) {
								target[props[i]] = {
									type: 'text',
									ref: source[props[i]].ref_to
								}
							} else if (typeof source[props[i]].ref_to == 'function') {
								target[props[i]] = {
									type: 'text',
									ref: source[props[i]].ref_to[0].toString()
								}

							} 
						} else {
							console.log('Unkown field `'+props[i]+'` - skipping.')
						}
						
					}
				}
			} 
			// array of fields .. or error in schema
			else {
				target[props[i]] = parse(source[props[i]]);
			}
		}
	}
	return target;
}
function field(key,type,data) {
	var obj = {};
	obj = {
		type: inputConversion[type]
	}
	
	marks.forEach(function(j){
		if(data[j])
			obj[j] = true;
	});
	
	filters.forEach(function(j){
		if(data[j]) {
			if(obj.filters === undefined)
				obj.filters = [];
			obj.filters.push(j);
		}
	});
	
	if(data.validate) {
		if(!Array.isArray(obj.validators))
			obj.validators = [];

		if(Array.isArray(data.validate)) {
			if(typeof data.validate[0].toString !== undefined) {
 				//var fn = data.validate.toString();
 				//var args = fn.match(/\([^\)]*/)[0].replace(/\(|\x20|\r|\n|\t/,'').split(',')
 				//var body = fn.match(/\{(.|[\r\n\t])*\}/)[0]
 				//	.replace(/^(\x20|[\r\n\t])*\{(\x20|[\r\n\t])*/,'')
 				//	.replace(/(\x20|[\r\n\t])*\}(\x20|[\r\n\t])*$/,'')
 				//	.replace(/[\r\n\t]*/,'')
 				//args.push(body);
				//obj.validators.push(['fn',data.validate[1],args]);
				obj.validators.push([data.validate[0].toString(),data.validate[1]])
			} else {
				console.log('Unkown function as default value for data key, using JSON.stringify, so check it plese in result.')
				obj.validators.push([JSON.stringify(data.validate[0]),data.validate[1]]);
			}

		} else {
			if(typeof data.validate.toString !== undefined) {
 				//var fn = data.validate.toString();
 				//var args = fn.match(/\([^\)]*/)[0].replace(/\(|\x20|\r|\n|\t/,'').split(',')
 				//var body = fn.match(/\{(.|[\r\n\t])*\}/)[0]
 				//	.replace(/^(\x20|[\r\n\t])*\{(\x20|[\r\n\t])*/,'')
 				//	.replace(/(\x20|[\r\n\t])*\}(\x20|[\r\n\t])*$/,'')
 				//	.replace(/[\r\n\t]*/,'')
 				//args.push(body);
				//obj.validators.push(['fn',null,args]);
				obj.validators.push(data.validate.toString())
			} else {
				console.log('Unkown function as default value for data key, using JSON.stringify, so check it plese in result.')
				obj.validators.push(JSON.stringify(data.validate));
			}
		}
	}

	if(data.enum) {
		obj.type = 'select';
		obj.options = data.enum;
	}
	
	if(data.fulltext)
		obj.type = 'textarea';
	
	if(data.default !== undefined) {

		switch(typeof data.default) {
			case 'function':
				var def = data.default.toString();
				if(def.match(/^function now/)) {
					obj.default = 'function() {return new Date()}'
				} else {
					obj.default = data.default;
				} 
			break;

			default:
				obj.default = data.default;
			break; 
		}
		
	}
	// build-in validators
	if(data.min) {
		if(!Array.isArray(obj.validators))
			obj.validators = [];
		obj.validators.push(['min','Value must be bigger than %i',data.min]);
	}
	if(data.max) {
		if(!Array.isArray(obj.validators))
			obj.validators = [];
		obj.validators.push(['max','Value must be less than %i',data.max]);
		
	}
	if(data.match !== undefined) {
		if(!Array.isArray(obj.validators))
			obj.validators = [];
		obj.validators.push(['match','Value must match provided pattern. '+data.match,data.max]);
	}
	return obj;
}